{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\t#nbc means naive bayes classifier\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data\n",
    "df_train = pd.read_csv('training.csv')\n",
    "train_set = pd.DataFrame(columns=['words', 'topic'])\n",
    "train_set['words'] = df_train['article_words'].str.replace(',',' ')\n",
    "train_set['topic'] = df_train['topic']\n",
    "\n",
    "# split the data to train set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_set['words'], train_set['topic'], test_size = 0.0526, random_state = 1)\n",
    "\n",
    "\n",
    "# encoder the y\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf\n",
    "\n",
    "#WordLevel tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word',token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(train_set['words'])\n",
    "xtrain_tfidf = tfidf_vect.transform(X_train)\n",
    "xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "# ngram tf-idf\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word',token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(train_set['words'])\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(X_train)\n",
    "xtest_tfidf_ngram = tfidf_vect_ngram.transform(X_test)\n",
    "\n",
    "#charlevel tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(train_set['words'])\n",
    "xtrain_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(X_train)\n",
    "xtest_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71555556 0.73666667 0.73333333 0.76333333 0.72222222 0.74\n",
      " 0.73222222 0.74777778 0.73333333 0.76555556]\n",
      "{'alpha': 0.01}\n",
      "Best score: 0.758\n",
      "NB, WordLevel TF-IDF:  0.76\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(10, shuffle=True, random_state=0)\n",
    "cv.get_n_splits(xtrain_tfidf)\n",
    "# cv.get_n_splits(X_train)\n",
    "scores = cross_val_score(MultinomialNB(), xtrain_tfidf, y_train, cv=cv)\n",
    "print(scores)\n",
    "parameters = {\n",
    "    'alpha': (1, 0.1, 0.01, 0.001, 0.0001),\n",
    "}\n",
    "grid_search = GridSearchCV(MultinomialNB(), parameters, n_jobs=1, cv = cv)\n",
    "grid_search.fit(xtrain_tfidf, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print (\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "m1 = MultinomialNB(alpha = 0.01).fit(xtrain_tfidf, y_train)\n",
    "predictions = m1.predict(xtest_tfidf)\n",
    "print(\"MNB, WordLevel TF-IDF: \",metrics.accuracy_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73333333 0.73333333 0.73222222 0.75555556 0.73       0.74222222\n",
      " 0.72333333 0.74777778 0.71888889 0.75444444]\n",
      "{'alpha': 0.1}\n",
      "Best score: 0.750\n",
      "NB, N-Gram Vectors:  0.764\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(10, shuffle=True, random_state=0)\n",
    "cv.get_n_splits(xtrain_tfidf_ngram)\n",
    "# cv.get_n_splits(X_train)\n",
    "scores = cross_val_score(MultinomialNB(), xtrain_tfidf_ngram, y_train, cv=cv)\n",
    "print(scores)\n",
    "parameters = {\n",
    "    'alpha': (1, 0.1, 0.01, 0.001, 0.0001),\n",
    "}\n",
    "grid_search = GridSearchCV(MultinomialNB(), parameters, n_jobs=1, cv = cv)\n",
    "grid_search.fit(xtrain_tfidf_ngram, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print (\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "m2 = MultinomialNB(alpha = 0.01).fit(xtrain_tfidf_ngram, y_train)\n",
    "predictions = m2.predict(xtest_tfidf_ngram)\n",
    "print( \"MNB, N-Gram Vectors: \",metrics.accuracy_score(predictions, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69444444 0.70888889 0.70444444 0.73       0.69777778 0.71444444\n",
      " 0.70555556 0.71       0.69888889 0.73111111]\n",
      "{'alpha': 0.01}\n",
      "Best score: 0.744\n",
      "NB, CharLevel Vectors:  0.756\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(10, shuffle=True, random_state=0)\n",
    "cv.get_n_splits(xtrain_tfidf_ngram_chars)\n",
    "# cv.get_n_splits(X_train)\n",
    "scores = cross_val_score(MultinomialNB(), xtrain_tfidf_ngram_chars, y_train, cv=cv)\n",
    "print(scores)\n",
    "parameters = {\n",
    "    'alpha': (1, 0.1, 0.01, 0.001, 0.0001),\n",
    "}\n",
    "grid_search = GridSearchCV(MultinomialNB(), parameters, n_jobs=1, cv = cv)\n",
    "grid_search.fit(xtrain_tfidf_ngram_chars, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print (\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "m3 = MultinomialNB(alpha = 0.01).fit(xtrain_tfidf_ngram_chars, y_train)\n",
    "predictions = m3.predict(xtest_tfidf_ngram_chars)\n",
    "print(\"MNB, CharLevel Vectors: \",metrics.accuracy_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35823\n",
      "35823\n"
     ]
    }
   ],
   "source": [
    "#Create a vector counter object\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(train_set['words'])\n",
    "\n",
    "#Use vector counter object to convert training set and validation set\n",
    "xtrain_count = count_vect.transform(X_train)\n",
    "xvalid_count = count_vect.transform(X_test)\n",
    "print(len(count_vect.get_feature_names()))\n",
    "print(len(count_vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71777778 0.75888889 0.73555556 0.77111111 0.73222222 0.72222222\n",
      " 0.71888889 0.73111111 0.72666667 0.74666667]\n",
      "{'alpha': 1}\n",
      "Best score: 0.736\n",
      "NB, Count Vectors:  0.738\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(10, shuffle=True, random_state=0)\n",
    "cv.get_n_splits(xtrain_count)\n",
    "scores = cross_val_score(MultinomialNB(), xtrain_count, y_train, cv=cv)\n",
    "print(scores)\n",
    "parameters = {\n",
    "    'alpha': (1, 0.1, 0.01, 0.001, 0.0001),\n",
    "}\n",
    "grid_search = GridSearchCV(MultinomialNB(), parameters, n_jobs=1, cv = cv)\n",
    "grid_search.fit(xtrain_count, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print (\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "m_count = MultinomialNB(alpha = 1).fit(xtrain_count, y_train)\n",
    "predictions = m1.predict(xvalid_count)\n",
    "print(\"NB, Count Vectors: \",metrics.accuracy_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.738\n",
      "0.738\n",
      "0.738\n",
      "0.738\n",
      "0.6583666424276271\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "      ARTS CULTURE ENTERTAINMENT       0.75      0.60      0.67         5\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       0.62      0.71      0.67         7\n",
      "                         DEFENCE       0.65      1.00      0.79        11\n",
      "                DOMESTIC MARKETS       0.67      0.33      0.44         6\n",
      "                   FOREX MARKETS       0.30      0.32      0.31        41\n",
      "                          HEALTH       0.58      0.78      0.67         9\n",
      "                       RRELEVANT       0.91      0.78      0.84       249\n",
      "                   MONEY MARKETS       0.53      0.70      0.61        99\n",
      "          SCIENCE AND TECHNOLOGY       0.60      1.00      0.75         3\n",
      "                  SHARE LISTINGS       0.71      0.42      0.53        12\n",
      "                          SPORTS       0.98      0.98      0.98        58\n",
      "\n",
      "                        accuracy                           0.74       500\n",
      "                       macro avg       0.66      0.69      0.66       500\n",
      "                    weighted avg       0.77      0.74      0.74       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_y = m_count.predict(xvalid_count)\n",
    "print(accuracy_score(y_test, predicted_y))\n",
    "print(precision_score(y_test, predicted_y, average='micro'))\n",
    "print(recall_score(y_test, predicted_y, average='micro'))\n",
    "print(f1_score(y_test, predicted_y, average='micro'))\n",
    "print(f1_score(y_test, predicted_y, average='macro'))\n",
    "target = ['ARTS CULTURE ENTERTAINMENT',\n",
    "    'BIOGRAPHIES PERSONALITIES PEOPLE',\n",
    "    'DEFENCE',\n",
    "    'DOMESTIC MARKETS',\n",
    "    'FOREX MARKETS',\n",
    "    'HEALTH',\n",
    "    'RRELEVANT',\n",
    "    'MONEY MARKETS',\n",
    "    'SCIENCE AND TECHNOLOGY',\n",
    "    'SHARE LISTINGS',\n",
    "    'SPORTS'\n",
    "    ]\n",
    "\n",
    "print(classification_report(y_test, predicted_y, target_names=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8, 3}\n",
      "0.724\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "      ARTS CULTURE ENTERTAINMENT       0.50      0.67      0.57         3\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       0.78      0.47      0.58        15\n",
      "                         DEFENCE       0.57      0.62      0.59        13\n",
      "                DOMESTIC MARKETS       0.00      0.00      0.00         2\n",
      "                   FOREX MARKETS       0.39      0.27      0.32        48\n",
      "                          HEALTH       0.83      0.71      0.77        14\n",
      "                       RRELEVANT       0.88      0.77      0.82       266\n",
      "                   MONEY MARKETS       0.43      0.80      0.56        69\n",
      "          SCIENCE AND TECHNOLOGY       0.00      0.00      0.00         3\n",
      "                  SHARE LISTINGS       1.00      0.14      0.25         7\n",
      "                          SPORTS       0.95      1.00      0.98        60\n",
      "\n",
      "                        accuracy                           0.72       500\n",
      "                       macro avg       0.58      0.50      0.49       500\n",
      "                    weighted avg       0.76      0.72      0.72       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "test_set = pd.DataFrame(columns=['words', 'topic'])\n",
    "x = df_test['article_words'].str.replace(',',' ')\n",
    "y = df_test['topic']\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(train_set['words'])\n",
    "x_count = count_vect.transform(x)\n",
    "\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "predicted_y = m1.predict(x_count)\n",
    "print(set(y) - set(predicted_y))\n",
    "# print(y_test, predicted_y)\n",
    "# print(m2.predict_proba(xtest_tfidf_ngram))\n",
    "print(accuracy_score(y, predicted_y))\n",
    "# print(precision_score(y, predicted_y, average='micro'))\n",
    "# print(recall_score(y, predicted_y, average='micro'))\n",
    "# print(f1_score(y, predicted_y, average='micro'))\n",
    "# print(f1_score(y, predicted_y, average='macro'))\n",
    "print(classification_report(y, predicted_y,target_names=target))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
